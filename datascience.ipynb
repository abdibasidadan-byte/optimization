
Predictive Analysis of Customer Behavior in E-Commerce: Prediction of Average Order Value and Identification of High-Value Customers

Description:
This data analysis project explores customer behavior on an e-commerce platform using a dataset containing key metrics such as session duration, product detail views, app transactions, add-to-cart rate per session, discount rate per visited products, credit card info saving, average order value ("avg order value"), and a high-value customer indicator ("high_value_customer").
The code is structured in several steps:
Data Preparation: Loading from the clipboard, cleaning (replacing commas with periods for decimals), numeric conversion, and encoding of categorical variables (e.g., yes/no via LabelEncoder).
Regression Modeling: Use of an XGBoost model to predict average order value, with evaluation via RMSE and R² on a test set (30% of the data). Visualizations include a scatter plot of predictions vs. actual values, a correlation matrix, a boxplot of average basket by card saving, and a histogram of prediction errors.
Classification Modeling: Logistic regression with L2 regularization to identify high-value customers, based on selected features (session duration, product views, etc.). Evaluation via ROC-AUC score and ROC curve.

data : https://github.com/Gayathri-Selvaganapathi/customer_churn_prediction/blob/main/data.csv
Acknowledgment to Gayathri-Selvaganapathi

# bash
#python -m pip install --upgrade pip
#pip install xgboost

import pandas as pd
import numpy as np
from io import StringIO
from sklearn.preprocessing import LabelEncoder

#
raw_data = pd.read_clipboard(sep=";")

# 
for col in raw_data.columns:
    if raw_data[col].dtype == "object":
        raw_data[col] = raw_data[col].str.replace(",", ".", regex=False)

# 
for col in raw_data.columns:
    try:
        raw_data[col] = pd.to_numeric(raw_data[col])
    except:
        pass

# 
encoder = LabelEncoder()
for col in raw_data.select_dtypes(include=["object"]).columns:
    raw_data[col] = encoder.fit_transform(raw_data[col])

print(raw_data.dtypes)
print(raw_data.head())



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
import numpy as np

#
X = raw_data.drop(columns=["avg order value", "user id"])  # on enlève la cible + identifiant
y = raw_data["avg order value"]

# 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 
model = XGBRegressor(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

#
model.fit(X_train, y_train)

# 
y_pred = model.predict(X_test)

# 
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print(f"RMSE : {rmse:.2f}")
print(f"R²   : {r2:.2f}")

import matplotlib.pyplot as plt
plt.scatter(y_test, y_pred, color="blue", alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--")
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Prédiction de avg order value avec XGBoost")
plt.show()

import seaborn as sns

plt.figure(figsize=(12,10))
sns.heatmap(raw_data.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Correlation Matrix")
plt.show()

sns.boxplot(x="credit card info save", y="avg order value", data=raw_data)
plt.xlabel("Saved Card")
plt.ylabel("Average Order Value")
plt.show()

errors = y_test - y_pred
plt.hist(errors, bins=10, color="skyblue", edgecolor="black")
plt.xlabel("Prediction Error")
plt.ylabel("Number of Customers")
plt.title("Distribution of Prediction Errors")
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# Variables explicatives (sélectionnées pour stabilité)
X = raw_data[['session duration', 'total product detail views',
              'app transactions', 'add to cart per session',
              'discount rate per visited products']]

y = raw_data['high_value_customer']

# Standardisation des variables
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Séparation train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42
)


clf = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)
clf.fit(X_train, y_train)

# Probabilités prédites pour la classe 1
y_prob = clf.predict_proba(X_test)[:, 1]

# Calcul du score ROC-AUC
roc_auc = roc_auc_score(y_test, y_prob)
print(f"ROC-AUC (Logistic Regression with L2): {roc_auc:.3f}")

# Tracé de la courbe ROC
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.figure(figsize=(6,6))
plt.plot(fpr, tpr, label=f"Logistic Regression (AUC = {roc_auc:.3f})")
plt.plot([0,1], [0,1], 'k--', label="Random")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Logistic Regression with L2 Regularization")
plt.legend(loc="lower right")
plt.show()
