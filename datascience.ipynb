{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analysis of Customer Behavior in E-Commerce: Prediction of Average Order Value and Identification of High-Value Customers\n",
    "\n",
    "## Description\n",
    "This data analysis project explores customer behavior on an e-commerce platform using a dataset containing key metrics such as session duration, product detail views, app transactions, add-to-cart rate per session, discount rate per visited products, credit card info saving, average order value (\"avg order value\"), and a high-value customer indicator (\"high_value_customer\").\n",
    "\n",
    "The code is structured in several steps:\n",
    "\n",
    "- **Data Preparation**: Loading from the CSV URL, cleaning (replacing commas with periods for decimals), numeric conversion, and encoding of categorical variables (e.g., yes/no via LabelEncoder).\n",
    "- **Regression Modeling**: Use of an XGBoost model to predict average order value, with evaluation via RMSE and R² on a test set (30% of the data). Visualizations include a scatter plot of predictions vs. actual values, a correlation matrix, a boxplot of average basket by card saving, and a histogram of prediction errors.\n",
    "- **Classification Modeling**: Logistic regression with L2 regularization to identify high-value customers, based on selected features (session duration, product views, etc.). Evaluation via ROC-AUC score and ROC curve.\n",
    "\n",
    "**Data Source**: [https://github.com/Gayathri-Selvaganapathi/customer_churn_prediction/blob/main/data.csv](https://github.com/Gayathri-Selvaganapathi/customer_churn_prediction/blob/main/data.csv)\n",
    "\n",
    "**Acknowledgment**: Gayathri-Selvaganapathi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation Requirements\n",
    "\n",
    "Run the following in a terminal or as a bash cell:\n",
    "```bash
    "python -m pip install --upgrade pip\n",
    "pip install xgboost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# === Load data from URL ===\n",
    "url = 'https://raw.githubusercontent.com/Gayathri-Selvaganapathi/customer_churn_prediction/main/data.csv'\n",
    "raw_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# === Replace commas with periods (decimal columns) ===\n",
    "for col in raw_data.columns:\n",
    "    if raw_data[col].dtype == \"object\":\n",
    "        raw_data[col] = raw_data[col].str.replace(\",\", \".\", regex=False)\n",
    "\n",
    "# === Convert to numeric when possible ===\n",
    "for col in raw_data.columns:\n",
    "    try:\n",
    "        raw_data[col] = pd.to_numeric(raw_data[col])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# === Encode categorical columns (yes/no, etc.) ===\n",
    "encoder = LabelEncoder()\n",
    "for col in raw_data.select_dtypes(include=[\"object\"]).columns:\n",
    "    raw_data[col] = encoder.fit_transform(raw_data[col])\n",
    "\n",
    "print(raw_data.dtypes)\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Modeling: Predicting Average Order Value with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# === Define X (features) and y (target) ===\n",
    "X = raw_data.drop(columns=[\"avg order value\", \"user id\"])  # remove target + identifier\n",
    "y = raw_data[\"avg order value\"]\n",
    "\n",
    "# === Split into train/test ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# === XGBoost model for regression ===\n",
    "model = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === Training ===\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === Predictions ===\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# === Evaluation ===\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred, color=\"blue\", alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
    "plt.xlabel(\"Valeurs réelles\")\n",
    "plt.ylabel(\"Valeurs prédites\")\n",
    "plt.title(\"Prédiction de avg order value avec XGBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(raw_data.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"credit card info save\", y=\"avg order value\", data=raw_data)\n",
    "plt.xlabel(\"Carte enregistrée\")\n",
    "plt.ylabel(\"Panier moyen\")\n",
    "plt.show()\n",
    "\n",
    "errors = y_test - y_pred\n",
    "plt.hist(errors, bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Erreur\")\n",
    "plt.ylabel(\"Nombre de clients\")\n",
    "plt.title(\"Distribution des erreurs de prédiction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Modeling: Identifying High-Value Customers with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Explanatory variables (selected for stability)\n",
    "X = raw_data[['session duration', 'total product detail views',\n",
    "              'app transactions', 'add to cart per session',\n",
    "              'discount rate per visited products']]\n",
    "\n",
    "y = raw_data['high_value_customer']\n",
    "\n",
    "# Standardization of variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic regression with L2 regularization (ridge)\n",
    "clf = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicted probabilities for class 1\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"ROC-AUC (Logistic Regression with L2): {roc_auc:.3f}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=f\"Logistic Regression (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Logistic Regression with L2 Regularization\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Identifier les clients à fort potentiel**\n",
    "Les deux modèles permettent de repérer les clients “high value”, mais chacun a ses avantages :\n",
    "- La régression logistique L2 est simple et interprétable : elle montre quelles variables comportementales influencent le plus le panier moyen.\n",
    "- XGBoost est plus puissant pour capturer des relations complexes ou non linéaires, utile si le comportement des clients est variable ou les données sont volumineuses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}